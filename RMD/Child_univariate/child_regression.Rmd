---
output: html_document
editor_options: 
  chunk_output_type: console
---
### Libraries
Some libraries
```{r}
library(psych)
library(whitening)
library("vioplot")
library("rpart")
library(multiColl)
library(car)

source("C:/Users/jtame/Documents/GitHub/LatentBiomarkers/RMD/RepeatedLinearCV.R")

```

### Data specs


```{r results = "asis"}
pander::pander(c(rows=nrow(dataframe),col=ncol(dataframe)-1))

varlist <- colnames(dataframe)
varlist <- varlist[varlist != outcome]

largeSet <- length(varlist) > 1500 
```


### Training and testing sets

```{r results = "asis", warning = FALSE}
set.seed(1)
trainsamples <- sample(nrow(dataframe),3*nrow(dataframe)/4)

trainingset <- dataframe[trainsamples,]
testingset <- dataframe[-trainsamples,]

pander::pander(t(summary(trainingset)))

varlist <- colnames(trainingset)
varlist <- varlist[varlist != outcome]
```


### Correlation Matrix of the Data

The heat map of the data

```{r results = "asis", warning = FALSE, dpi=300, fig.height= 5.0, fig.width= 7.0}
par(op)


  par(cex=0.6,cex.main=0.85,cex.axis=0.7)
  cormat <- cor(testingset[,varlist],method="pearson")
  cormat[is.na(cormat)] <- 0
  gplots::heatmap.2(abs(cormat),
                    trace = "none",
  #                  scale = "row",
                    mar = c(5,5),
                    col=rev(heat.colors(5)),
                    main = "Original Correlation",
                    cexRow = cexheat,
                    cexCol = cexheat,
                     srtCol=45,
                     srtRow=45,
                    key.title=NA,
                    key.xlab="|Pearson Correlation|",
                    xlab="Feature", ylab="Feature")
  diag(cormat) <- 0
  pander::pander(max(abs(cormat)))
par(op)

```


###  Decorrelating using ILAA

ILAA bootstrapped training and testing sets

```{r results = "asis", warning = FALSE}
trainage_DE <- ILAA(trainingset,thr=thro,Outcome=outcome,verbose=TRUE,bootstrap=30)

testage_DE <- predictDecorrelate(trainage_DE,testingset)


```

### The Formulas

Generating the formulas

```{r results = "asis", warning = FALSE}

theLaFormulas <- getLatentCoefficients(trainage_DE)

theCharformulas <- attr(theLaFormulas,"LatentCharFormulas")
pander::pander(as.matrix(theCharformulas))

```


### Formulas Network

Displaying the features associations

```{r  results = "asis", warning = FALSE, dpi=300, fig.height= 6.0, fig.width= 6.0}
par(op)

  transform <- attr(trainage_DE,"UPLTM") != 0
  colnames(transform) <- str_remove_all(colnames(transform),"La_")
  transform <- abs(transform*cor(trainingset[,rownames(transform)])) # The weights are proportional to the observed correlation
  
  
  VertexSize <- attr(trainage_DE,"fscore") # The size depends on the variable independence relevance (fscore)
  names(VertexSize) <- str_remove_all(names(VertexSize),"La_")
  VertexSize <- 10*(VertexSize-min(VertexSize))/(max(VertexSize)-min(VertexSize)) # Normalization
  
  gr <- graph_from_adjacency_matrix(transform,mode = "directed",diag = FALSE,weighted=TRUE)
  gr$layout <- layout_with_fr
  
  fc <- cluster_optimal(gr)
  plot(fc, gr,
       edge.width = 2*E(gr)$weight,
       vertex.size=VertexSize,
       edge.arrow.size=0.5,
       edge.arrow.width=0.75,
       vertex.label.cex=0.5,
       vertex.label.dist=1,
       main="Feature Association")

par(op)

      varratios <- attr(trainage_DE,"VarRatio")
      names(varratios) <- str_remove_all(names(varratios),"La_")
      fscores <- attr(trainage_DE,"fscore") 
      names(fscores) <- str_remove_all(names(fscores),"La_")
      clustable <- as.data.frame(cbind(Variable=fc$names,
                                       Formula=as.character(theCharformulas[paste("La_",fc$names,sep="")]),
                                       Cluster=fc$membership,
                                       ResidualVariance=round(varratios[fc$names],3),
                                       Fscore=round(fscores[fc$names],3)
                                       )
                                 )
      rownames(clustable) <- str_replace_all(rownames(clustable),"__","_")
      clustable$Variable <- NULL
      clustable$Cluster <- as.integer(clustable$Cluster)
      clustable$ResidualVariance <- as.numeric(clustable$ResidualVariance)
      clustable$Fscore <- as.numeric(clustable$Fscore)
      clustable <- clustable[order(-clustable$Fscore),]
      clustable <- clustable[order(clustable$Cluster),]

pander::pander(as.matrix(clustable))
```

### Correlation Matrix of the Data

The heat map of the ILAA transformed data

```{r results = "asis", warning = FALSE, dpi=300, fig.height= 5.0, fig.width= 7.0}
par(op)

varlistDe <- colnames(trainage_DE)
varlistDe <- varlistDe[varlistDe != outcome]

  par(cex=0.6,cex.main=0.85,cex.axis=0.7)

# Training    
  cormat <- cor(trainage_DE[,varlistDe],method="pearson")
  cormat[is.na(cormat)] <- 0
  gplots::heatmap.2(abs(cormat),
                    trace = "none",
                    mar = c(5,5),
                    col=rev(heat.colors(5)),
                    main = "Training: After ILAA Correlation",
                    cexRow = cexheat,
                    cexCol = cexheat,
                     srtCol=45,
                     srtRow=45,
                    key.title=NA,
                    key.xlab="|Pearson Correlation|",
                    xlab="Feature", ylab="Feature")
  diag(cormat) <- 0
  pander::pander(max(abs(cormat)))

  par(op)
# Testing

  cormat <- cor(testage_DE[,varlistDe],method="pearson")
  cormat[is.na(cormat)] <- 0
  gplots::heatmap.2(abs(cormat),
                    trace = "none",
                    mar = c(5,5),
                    col=rev(heat.colors(5)),
                    main = "Testing: After ILAA Correlation",
                    cexRow = cexheat,
                    cexCol = cexheat,
                     srtCol=45,
                     srtRow=45,
                    key.title=NA,
                    key.xlab="|Pearson Correlation|",
                    xlab="Feature", ylab="Feature")
  diag(cormat) <- 0
  pander::pander(max(abs(cormat)))

  par(op)

  
```


### Modeling

#### Modeling outcome using raw set

```{r results = "asis", warning = FALSE}
outcomeModel <- LASSO_1SE(formula(paste(outcome,"~.")),trainingset);
predOutcome <- predict(outcomeModel,testingset)
pander::pander(as.matrix(outcomeModel$coef))

```

#### Modeling  outcome using decorrelated set

```{r results = "asis", warning = FALSE, dpi=300, fig.height= 5.0, fig.width= 7.0}
outcomeModel_DE <- LASSO_1SE(formula(paste(outcome,"~.")),trainage_DE);
predOutcome_DE <- predict(outcomeModel_DE,testage_DE)

pander::pander(as.matrix(outcomeModel_DE$coef),caption="ILAA Coef")
obsCoef <- getObservedCoef(trainage_DE,outcomeModel_DE)
pander::pander(as.matrix(obsCoef$coef),caption="ILAA Modeling")


pander::pander(cor.test(predOutcome,testingset[,outcome]),caption="Raw Model")
pander::pander(cor.test(predOutcome_DE,testage_DE[,outcome]),caption="ILAA-based Model")

```

#### Univariate t-test

```{r results = "asis", warning = FALSE, dpi=300, fig.height= 5.0, fig.width= 7.0}

rawunittvalues <- apply(as.matrix(testingset[,names(outcomeModel$coef)[-1]]),2,tvals,testingset[,outcome])
names(rawunittvalues) <- names(outcomeModel$coef)[-1]

deunittvalues <- apply(testage_DE[,names(outcomeModel_DE$coef)[-1]],2,tvals,testingset[,outcome])
```


#### Comparing summaries

```{r results = "asis", warning = FALSE, dpi=300, fig.height= 4.0, fig.width= 7.0}

psig <- 0.1/(ncol(testingset)-1)
lmod <- lm(paste(outcome,"~."),testingset[,c(outcome,names(outcomeModel$coef)[-1])])
sm <- summary(lmod)
if (length(lmod$coef)>10)
{
  sm$coefficients[1,4] <- 1.0
  gcoef <- lmod$coef[sm$coefficients[,4]<psig]
  lmod <- lm(paste(outcome,"~."),testingset[,c(outcome,names(gcoef))])
}

sm <- summary(lmod)
smcoef <- as.data.frame(sm$coefficients)
smcoef <- smcoef[order(-abs(smcoef[,3])),]
smcoef$Uni_t_values <- rawunittvalues[rownames(smcoef)]
smcoef <- smcoef[!is.na(smcoef$Uni_t_values),]
if (nrow(smcoef)>10) smcoef <- smcoef[smcoef[,4]<psig,]

pander::pander(smcoef)
pander::pander(t(c(R2=sm$r.squared,adj_R2=sm$adj.r.squared)))
pander::pander(c(numvar=nrow(smcoef)))


lmod_DE <- lm(paste(outcome,"~."),testage_DE[,c(outcome,names(outcomeModel_DE$coef)[-1])])
sm <- summary(lmod_DE)
if (length(lmod_DE$coef)>10)
{
  sm$coefficients[1,4] <- 1.0
  gcoef <- lmod_DE$coef[sm$coefficients[,4]<psig]
  lmod_DE <- lm(paste(outcome,"~."),testage_DE[,c(outcome,names(gcoef))])
}

sm <- summary(lmod_DE)
lacoef <- as.data.frame(sm$coefficients)
lacoef <- lacoef[order(-abs(lacoef[,3])),]
lacoef$Uni_t_values <- deunittvalues[rownames(lacoef)]
lacoef <- lacoef[!is.na(lacoef$Uni_t_values),]
if (nrow(lacoef)>10) lacoef <- lacoef[lacoef[,4]<psig,]

lacoef$formula <- theCharformulas[rownames(lacoef)]
pander::pander(lacoef)
pander::pander(t(c(R2=sm$r.squared,adj_R2=sm$adj.r.squared)))
pander::pander(c(numvar=nrow(lacoef)))


xvals <-c(min(c(deunittvalues,rawunittvalues))-3,max(c(deunittvalues,rawunittvalues))+3)

par(mfrow=c(1,2),cex=0.5)

plot(smcoef[,c(3,5)],
     main="Raw: Univariate t-values vs regression t-values",
     xlim=xvals,
     ylim=xvals
     )

lmtvals <- lm(smcoef[,5]~smcoef[,3])
pred <- lmtvals$coefficients[1] + lmtvals$coefficients[2] * xvals
lines(x=xvals,y=pred,col="red")
text(xvals[1]+(xvals[2]-xvals[1])/2,xvals[2]-1,sprintf("Slope= %.2f",lmtvals$coefficients[2]))


plot(lacoef[-1,c(3,5)],
     main="ILAA: Univariate t-values vs regression t-values",
     xlim=xvals,
     ylim=xvals
     )

lmtvals <- lm(lacoef[,5]~lacoef[,3])
pred <- lmtvals$coefficients[1] + lmtvals$coefficients[2] * xvals
lines(x=xvals,y=pred,col="red")
text(xvals[1]+(xvals[2]-xvals[1])/2,xvals[2]-1,sprintf("Slope= %.2f",lmtvals$coefficients[2]))

#pander::pander(summary(lmtvals))


pander::pander(cor.test(smcoef[,3],smcoef[,5]))

pander::pander(cor.test(lacoef[,3],lacoef[,5]))

par(op)




```

#### Ploting predictions

```{r results = "asis", warning = FALSE, dpi=300, fig.height= 3.0, fig.width= 7.0}
par(mfrow=c(1,3),cex=0.5)
plot(lmod$fitted.values,predOutcome,main="Raw: lm train predict vs. test predict",xlab="Train",ylab="Test")
plot(lmod_DE$fitted.values,predOutcome_DE,main="ILAA: lm train predict vs. test predict",xlab="Train",ylab="Test")

plot(predOutcome,predOutcome_DE,xlab="Raw Predicted",ylab="ILAA Predicted",main="Raw vs. ILAA")

par(op)

```


### CV 

#### test Correlations

```{r results = "asis", warning = FALSE, dpi=300, fig.height= 5, fig.width= 7.0}
par(op)
corresults <- CV_IDeA(dataframe,outcome,loops=loops)

mintvals <- min(c(min(corresults$rawtValues),min(corresults$detValues)))
maxvals <- max(c(max(corresults$rawtValues),max(corresults$detValues)))
xvals <- c(mintvals,maxvals)

vioplot(list(raw=corresults$testRawCorrelations,ILAA=corresults$testDeCorrelations),
        ylab="Pearson Correlation",
        main="Test Correlations")

pander::pander(t.test(corresults$testDeCorrelations,corresults$testRawCorrelations,paired=TRUE))

sylim <- c(0,min(c(20,max(corresults$VIFRaw))))
vioplot(list(raw=corresults$VIFRaw,ILAA=corresults$VIFDe),
        ylab="VIF",
        ylim=sylim,
        main="Test VIF")


pander::pander(summary(cbind(raw=corresults$VIFRaw,ILAA=corresults$VIFDe)))
summary(corresults$VIFRaw)


```

### The t-values

```{r results = "asis", warning = FALSE, dpi=300, fig.height= 3.5, fig.width= 7.0}

par(op)
par(mfrow=c(1,2),cex=0.5)
plot(corresults$rawtValues,
     main="Raw: Univariate t-values vs Model t-values",
     xlab="Univariate",
     ylab="Model",
     xlim=xvals,
     ylim=xvals)

lmtvals <- lm(Model~.,corresults$rawtValues)
pred <- lmtvals$coefficients[1] + lmtvals$coefficients[2] * xvals
lines(x=xvals,y=pred,col="red")
text(xvals[1]+(xvals[2]-xvals[1])/2,xvals[2]-1,sprintf("Slope= %.2f",lmtvals$coefficients[2]))

pander::pander(summary(lmtvals))

plot(corresults$detValues,
      main="ILAA: Univariate t-values vs Model t-values",
     xlab="Univariate",
     ylab="Model",
     xlim=xvals,
     ylim=xvals)

lmtvals <- lm(Model~.,corresults$detValues)
pred <- lmtvals$coefficients[1] + lmtvals$coefficients[2] * xvals
lines(x=xvals,y=pred,col="red")
text(xvals[1]+(xvals[2]-xvals[1])/2,xvals[2]-1,sprintf("Slope= %.2f",lmtvals$coefficients[2]))

pander::pander(summary(lmtvals))

```

