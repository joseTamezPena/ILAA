---
title: "Decorrelation-Based Feature Discovery: Parkinsons"
author: "Jose Tamez"
date: "2022-10-02"
output:
  html_document: 
    toc: yes
    fig_caption: yes
    number_sections: yes
  word_document: 
    reference_docx: WordStyle_FRESA.docx
    toc: yes
    fig_caption: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(collapse = TRUE, warning = FALSE, message = FALSE,comment = "#>")

```

# Effect of UPSTM-Based Decorrelation on Feature Discovery

Here I showcase of to use BSWiMS feature selection/modeling function coupled with Goal Driven Sparse Transformation Matrix (UPSTM) as a pre-processing step to decorrelate highly correlated features. The aim(s) are:

1.  To improve model performance by uncovering the hidden information between correlated features.

2.  To simplify the interpretation of the machine learning models.

This demo will use:

-   *FRESA.CAD::IDeA()*. For Decorrelation of Multidimensional data sets

    -   *FRESA.CAD::getLatentCoefficients()*. For the extraction of the model of the newly discovered of decorrelated features.


-   *heatmap.2()*. For displaying the correlation matrix



### Loading the libraries

```{r}
library("FRESA.CAD")
library(readxl)
library(igraph)
library(umap)
library(tsne)
library(entropy)

op <- par(no.readonly = TRUE)
pander::panderOptions('digits', 3)
pander::panderOptions('table.split.table', 400)
pander::panderOptions('keep.trailing.zeros',TRUE)

```

## Material and Methods

Data from the speech features 


## The Data

```{r}

pd_speech_features <- as.data.frame(read_excel("~/GitHub/FCA/Data/pd_speech_features.xlsx",sheet = "pd_speech_features", range = "A2:ACB758"))




```

### The Average of the Three Repetitions

Each subject had three repeated observations. Here I'll use the average of the three experiments per subject.

```{r results = "asis", warning = FALSE, dpi=300, fig.height= 6.0, fig.width= 8.0}
rep1Parkison <- subset(pd_speech_features,RID==1)
rownames(rep1Parkison) <- rep1Parkison$id
rep1Parkison$id <- NULL
rep1Parkison$RID <- NULL
rep1Parkison[,1:ncol(rep1Parkison)] <- sapply(rep1Parkison,as.numeric)

rep2Parkison <- subset(pd_speech_features,RID==2)
rownames(rep2Parkison) <- rep2Parkison$id
rep2Parkison$id <- NULL
rep2Parkison$RID <- NULL
rep2Parkison[,1:ncol(rep2Parkison)] <- sapply(rep2Parkison,as.numeric)

rep3Parkison <- subset(pd_speech_features,RID==3)
rownames(rep3Parkison) <- rep3Parkison$id
rep3Parkison$id <- NULL
rep3Parkison$RID <- NULL
rep3Parkison[,1:ncol(rep3Parkison)] <- sapply(rep3Parkison,as.numeric)

whof <- !(colnames(rep1Parkison) %in% c("gender","class"));
avgParkison <- rep1Parkison;
avgParkison[,whof] <- (rep1Parkison[,whof] + rep2Parkison[,whof] + rep3Parkison[,whof])/3

## I apply the log transform to the data
##avgParkison[,whof] <- signedlog(avgParkison[,whof])
#avgParkison[,whof] <- FRESAScale(avgParkison[,whof],method="OrderLogit")$scaledData
#pander::pander(table(avgParkison$class))

signedlog <- function(x) { return (sign(x)*log(abs(1.0e12*x)+1.0))}
whof <- !(colnames(avgParkison) %in% c("gender","class"));
avgParkison[,whof] <- signedlog(avgParkison[,whof])


```

#### Standarize the names for the reporting

```{r results = "asis"}
dataframe <- avgParkison
outcome <- "class"

trainFraction <- 0.5
rhoThreshold <- 0.8
TopVariables <- 5
aucTHR <- 0.75

set.seed(5)
trainSample <- sample(nrow(dataframe),nrow(dataframe)*trainFraction)

trainDataFrame <- dataframe[trainSample,]
testDataFrame <- dataframe[-trainSample,]

tb <- table(dataframe[,outcome])
classes <- c("Neg","Pos")
names(classes) <- names(tb)



varlist <- colnames(trainDataFrame)
varlist <- varlist[varlist != "class"]

tokeep <- c(as.character(correlated_Remove(trainDataFrame,varlist,thr=0.9999)),"class")
trainDataFrame <- trainDataFrame[,tokeep]
testDataFrame <- testDataFrame[,tokeep]

trainScale <- FRESAScale(trainDataFrame,method="OrderLogit")
trainDataFrame <- trainScale$scaledData
table(trainDataFrame$class)

testDataFrame <- FRESAScale(testDataFrame,method="OrderLogit",refMean=trainScale$refMean,refDisp=trainScale$refDisp)$scaledData
table(testDataFrame$class)


```

### Data specs

```{r results = "asis"}
pander::pander(c(rows=nrow(dataframe),col=ncol(dataframe)-1))
pander::pander(table(dataframe[,outcome]))
pander::pander(table(trainDataFrame[,outcome]))
pander::pander(table(testDataFrame[,outcome]))

varlist <- colnames(trainDataFrame)
varlist <- varlist[varlist != outcome]

```





## The heatmap of the data

```{r results = "asis", warning = FALSE, dpi=300, fig.height= 5.0, fig.width= 7.0}

hmdf <- testDataFrame;
hmdf$class <- as.numeric(as.factor(testDataFrame$class))


hm <- heatMaps(data=hmdf,
               Outcome="class",
               Scale=TRUE,
               hCluster = "row",
               xlab="Feature",
               ylab="Sample",
               cexCol=0.15,
               cexRow=0.25
               )
par(op)

```

### The UMAP
```{r results = "asis", warning = FALSE, dpi=300, fig.height= 5.0, fig.width= 7.0}
raincolors <- rainbow(length(classes))
names(raincolors) <- classes
datasetframe.umap = umap(scale(trainDataFrame[,varlist]),n_components=2)
plot(datasetframe.umap$layout,xlab="U1",ylab="U2",main="UMAP: Original",t='n')
text(datasetframe.umap$layout,labels=trainDataFrame$class,col=raincolors[trainDataFrame$class+1])


```


#### Correlation Matrix of the Decorrelated Test Data

The heat map of the testing set.

```{r results = "asis", warning = FALSE, dpi=300, fig.height= 5.0, fig.width= 7.0}

par(cex=0.6,cex.main=0.85,cex.axis=0.7)
cormat <- cor(testDataFrame[,varlist],method="pearson")
cormat[is.na(cormat)] <- 0
diag(cormat) <- 0
gplots::heatmap.2(abs(cormat),
                  trace = "none",
#                  scale = "row",
                  mar = c(5,5),
                  col=rev(heat.colors(5)),
                  main = "Original Correlation",
                  cexRow = 0.15,
                  cexCol = 0.15,
                  key.title=NA,
                  key.xlab="Pearson Correlation",
                  xlab="Feature", ylab="Feature")

```

## The decorrelation

```{r}
trainDecor <- IDeA(trainDataFrame,thr=rhoThreshold,verbose=TRUE)
testDecor <- predictDecorrelate(trainDecor,testDataFrame)
varlistc <- colnames(testDecor)[colnames(testDecor) != outcome]

pander::pander(sum(apply(testDataFrame[,varlist],2,var)))
pander::pander(sum(apply(testDecor[,varlistc],2,var)))
pander::pander(entropy(discretize(unlist(testDataFrame[,varlist]), 256)))
pander::pander(entropy(discretize(unlist(testDecor[,varlistc]), 256)))

cormat <- cor(testDecor[,varlistc],method="pearson")
cormat[is.na(cormat)] <- 0
diag(cormat) <- 0

gplots::heatmap.2(abs(cormat),
                  trace = "none",
                  mar = c(5,5),
                  col=rev(heat.colors(5)),
                  main = "Correlation after IDeA",
                  cexRow = 0.15,
                  cexCol = 0.15,
                  key.title=NA,
                  key.xlab="Pearson Correlation",
                  xlab="Feature", ylab="Feature")

par(op)

```

## The heatmap of the decorrelated data

```{r results = "asis", warning = FALSE, dpi=300, fig.height= 5.0, fig.width= 7.0}
hmdf <- testDecor;
hmdf$class <- as.numeric(as.factor(testDecor$class))

hm <- heatMaps(data=hmdf,
               Outcome="class",
               Scale=TRUE,
               hCluster = "row",
               cexRow = 0.15,
               cexCol = 0.15,
               xlab="Feature",
               ylab="Sample")
par(op)

```

### The decorralted UMAP
```{r results = "asis", warning = FALSE, dpi=300, fig.height= 5.0, fig.width= 7.0}

datasetframe.umap = umap(scale(trainDecor[,varlistc]),n_components=2)
plot(datasetframe.umap$layout,xlab="U1",ylab="U2",main="UMAP: After IDeA",t='n')
text(datasetframe.umap$layout,labels=trainDecor$class,col=raincolors[trainDecor$class+1])

```


### The decorrelation matrix

```{r results = "asis", warning = FALSE, dpi=300, fig.height= 5.0, fig.width= 7.0}

par(cex=0.6,cex.main=0.85,cex.axis=0.7)

UPSTM <- attr(trainDecor,"UPSTM")

gplots::heatmap.2(1.0*(abs(UPSTM)>0),
                  trace = "none",
                  mar = c(5,5),
                  col=rev(heat.colors(5)),
                  main = "Decorrelation matrix",
                  cexRow = 0.15,
                  cexCol = 0.15,
                  key.title=NA,
                  key.xlab="|Beta|>0",
                  xlab="Output Feature", ylab="Input Feature")

par(op)

```

### Univariate

```{r results = "asis", warning = FALSE, dpi=300, fig.height= 6.0, fig.width= 5.0}


btrain <- trainDataFrame
btrain$class <- 1.0*(btrain$class == names(classes[1]))
univarTrain <- uniRankVar(varlist,
	           "class~1",
	           "class",
	           btrain,
	           rankingTest="AUC")

btest <- testDataFrame
btest$class <- 1.0*(btest$class == names(classes[1]))
univarTest <- uniRankVar(varlist,
	           "class~1",
	           "class",
	           btest,
	           rankingTest="AUC")

rawadjTrainpvalues <- names(univariate_Wilcoxon(trainDataFrame,outcome,pvalue=0.05))
minROCAUCRaw <- min(univarTrain$orderframe[rawadjTrainpvalues,"ROCAUC"])
rawadjTestpvalues <- univarTest$orderframe$Name[univarTest$orderframe$ROCAUC >= minROCAUCRaw]
pander::pander(c(train=length(rawadjTrainpvalues)))
pander::pander(c(test=length(rawadjTestpvalues)))
TDR_Raw <- sum(rawadjTestpvalues %in% rawadjTrainpvalues)/length(rawadjTrainpvalues)
pander::pander(c(TDR=jaccard))


DeadTestpvalues <- univariate_Wilcoxon(testDecor,outcome,pvalue=0.05)

dtrain <- trainDecor
dtrain$class <- 1.0*(dtrain$class == names(classes[1]))
univarDeTrain <- uniRankVar(varlistc,
	           "class~1",
	           "class",
	           dtrain,
	           rankingTest="AUC",
	           )

dtest <- testDecor
dtest$class <- 1.0*(dtest$class == names(classes[1]))
univarDeTest <- uniRankVar(varlistc,
	           "class~1",
	           "class",
	           dtest,
	           rankingTest="AUC",
	           )


rawadjTestpvalues <- names(univariate_Wilcoxon(trainDecor,outcome,pvalue=0.05))
minROCAUCDe <- min(univarDeTrain$orderframe[rawadjTestpvalues,"ROCAUC"])
deadjTestpvalues <- univarDeTest$orderframe$Name[univarDeTest$orderframe$ROCAUC >= minROCAUCDe]

pander::pander(c(train=length(deadjTrainpvalues)))
pander::pander(c(test=length(deadjTestpvalues)))
TDR_DE <- sum(deadjTestpvalues %in% deadjTrainpvalues)/length(deadjTrainpvalues)
pander::pander(c(TDR=TDR_DE))


```


### Final Table 

```{r results = "asis"}

univariate_columns <- c("caseMean","caseStd","controlMean","controlStd","controlKSP","ROCAUC")

##topfive
topvar <- c(1:length(varlist)) <= TopVariables
pander::pander(univarTest$orderframe[topvar,univariate_columns])


pwilvalue <- univarDeTest$orderframe$FRes.p
valroc <- univarDeTest$orderframe$ROCAUC > aucTHR & topvar



finalTable <- univarDeTest$orderframe[valroc,univariate_columns]

dc <- getLatentCoefficients(trainDecor)
fscores <- attr(trainDecor,"fscore")

theFormulas <- dc[rownames(finalTable)]
deFromula <- character(length(theFormulas))
names(deFromula) <- rownames(finalTable)

dx <- names(deFromula)[1]
for (dx in names(deFromula))
{
  coef <- theFormulas[[dx]]
  cname <- names(theFormulas[[dx]])
  names(cname) <- cname
  for (cf in names(coef))
  {
    if (cf != dx)
    {
      if (coef[cf]>0)
      {
        deFromula[dx] <- paste(deFromula[dx],
                               sprintf("+ %5.3f*%s",coef[cf],cname[cf]))
      }
      else
      {
        deFromula[dx] <- paste(deFromula[dx],
                               sprintf("%5.3f*%s",coef[cf],cname[cf]))
      }
    }
  }
}
orgnamez <- rownames(finalTable)
orgnamez <- str_remove_all(orgnamez,"La_")
finalTable$DecorFormula <- deFromula[rownames(finalTable)]
finalTable$fscores <- fscores[rownames(finalTable)]
finalTable$Qvalue <- DeadTestpvalues[rownames(finalTable)]
  
pander::pander(finalTable)

```

### ML Lasso

```{r  results = "asis", warning = FALSE, dpi=300, fig.height= 6.0, fig.width= 5.0}
mlLasso <- LASSO_1SE(class~.,trainDataFrame,family="binomial")
predRaw <- predict(mlLasso,testDataFrame)
perfRaw <- predictionStats_binary(cbind(testDataFrame$class,predRaw),"Lasso RAW")
pander::pander(univarTest$orderframe[mlLasso$selectedfeatures,univariate_columns])


mlLassoDe <- LASSO_1SE(class~.,trainDecor,family="binomial")
predDe <- predict(mlLassoDe,testDecor)
perfDe <- predictionStats_binary(cbind(testDecor$class,predDe),"Lasso IDeA")
pander::pander(univarDeTest$orderframe[mlLassoDe$selectedfeatures,univariate_columns])

pander::pander(roc.test(perfRaw$ROC.analysis$roc.predictor,perfDe$ROC.analysis$roc.predictor))

```

### Summary
```{r results = "asis"}
selectedRaw <- length(rawadjTrainpvalues)
selectedDe <- length(deadjTrainpvalues)
sumPerf <- rbind(c(selectedRaw,TDR_Raw,minROCAUCRaw),c(selectedDe,TDR_DE,minROCAUCDe))
colnames(sumPerf) <- c("Selected","TDR","ROCAUC")
rownames(sumPerf) <- c("Raw","Decorrelated")
pander::pander(sumPerf)
```

